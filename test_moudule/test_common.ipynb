{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature_Fusion_Module(\n  (fc1): Linear(in_features=512, out_features=6, bias=True)\n)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'batchsize' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ec6288f4efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mffm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeature_Fusion_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batchsize' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature_Fusion_Module(\n  (fc1): Linear(in_features=512, out_features=6, bias=True)\n)\ntorch.Size([8, 512])\ntensor([[2.6564e-04, 9.0955e-05, 2.1615e-02, 1.6105e-03, 9.8068e-06, 9.0712e-01],\n        [9.9885e-01, 1.0000e+00, 5.5381e-02, 2.3682e-16, 7.2926e-02, 9.7148e-04],\n        [1.0600e-06, 2.3232e-01, 4.6988e-13, 9.4187e-01, 5.4587e-03, 1.0000e+00],\n        [9.9605e-01, 9.8943e-01, 1.1381e-05, 9.9995e-01, 2.1420e-10, 4.0579e-01],\n        [1.0000e+00, 9.4973e-01, 1.0000e+00, 9.9984e-01, 6.8920e-08, 9.9995e-01],\n        [4.4165e-17, 9.9347e-01, 2.7593e-02, 9.3344e-03, 2.5337e-05, 4.6086e-08],\n        [9.9907e-01, 1.4795e-07, 7.7169e-01, 4.6511e-02, 3.1844e-10, 1.1207e-01],\n        [9.9727e-01, 9.9571e-01, 1.0000e+00, 7.9550e-01, 1.7571e-08, 9.9780e-01]],\n       grad_fn=<SigmoidBackward>)\ntorch.Size([8, 6])\ncomplete check.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        if m.affine:\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class Feature_Fusion_Module(nn.Module):\n",
    "    # 自定义特征融合模块\n",
    "    def __init__(self, ** kwargs):\n",
    "        super(Feature_Fusion_Module, self).__init__()\n",
    "        # Classifier for each stripe\n",
    "        self.fc1 = nn.Linear(512, 6)\n",
    "        self.fc1.apply(weights_init_kaiming)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "ffm = Feature_Fusion_Module()\n",
    "print(ffm)\n",
    "rd = torch.randn(batchsize, 512)\n",
    "print(rd.shape)\n",
    "res = ffm(rd)\n",
    "print(res)\n",
    "print(res.shape)\n",
    "print('complete check.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_H = []  # contains 6 ([N, 256, 1])\n",
    "for i in range(6):\n",
    "    stripe_features_H = torch.randn(8,256,1)\n",
    "    features_H.append(stripe_features_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_factor= res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[2.6564e-04, 9.0955e-05, 2.1615e-02, 1.6105e-03, 9.8068e-06, 9.0712e-01],\n        [9.9885e-01, 1.0000e+00, 5.5381e-02, 2.3682e-16, 7.2926e-02, 9.7148e-04],\n        [1.0600e-06, 2.3232e-01, 4.6988e-13, 9.4187e-01, 5.4587e-03, 1.0000e+00],\n        [9.9605e-01, 9.8943e-01, 1.1381e-05, 9.9995e-01, 2.1420e-10, 4.0579e-01],\n        [1.0000e+00, 9.4973e-01, 1.0000e+00, 9.9984e-01, 6.8920e-08, 9.9995e-01],\n        [4.4165e-17, 9.9347e-01, 2.7593e-02, 9.3344e-03, 2.5337e-05, 4.6086e-08],\n        [9.9907e-01, 1.4795e-07, 7.7169e-01, 4.6511e-02, 3.1844e-10, 1.1207e-01],\n        [9.9727e-01, 9.9571e-01, 1.0000e+00, 7.9550e-01, 1.7571e-08, 9.9780e-01]],\n       grad_fn=<SigmoidBackward>)\ntensor([[[2.6564e-04],\n         [2.6564e-04],\n         [2.6564e-04],\n         ...,\n         [2.6564e-04],\n         [2.6564e-04],\n         [2.6564e-04]],\n\n        [[9.9885e-01],\n         [9.9885e-01],\n         [9.9885e-01],\n         ...,\n         [9.9885e-01],\n         [9.9885e-01],\n         [9.9885e-01]],\n\n        [[1.0600e-06],\n         [1.0600e-06],\n         [1.0600e-06],\n         ...,\n         [1.0600e-06],\n         [1.0600e-06],\n         [1.0600e-06]],\n\n        ...,\n\n        [[4.4165e-17],\n         [4.4165e-17],\n         [4.4165e-17],\n         ...,\n         [4.4165e-17],\n         [4.4165e-17],\n         [4.4165e-17]],\n\n        [[9.9907e-01],\n         [9.9907e-01],\n         [9.9907e-01],\n         ...,\n         [9.9907e-01],\n         [9.9907e-01],\n         [9.9907e-01]],\n\n        [[9.9727e-01],\n         [9.9727e-01],\n         [9.9727e-01],\n         ...,\n         [9.9727e-01],\n         [9.9727e-01],\n         [9.9727e-01]]], grad_fn=<DivBackward0>)\ntorch.Size([8, 256, 1])\ntensor([[[9.0955e-05],\n         [9.0955e-05],\n         [9.0955e-05],\n         ...,\n         [9.0955e-05],\n         [9.0955e-05],\n         [9.0955e-05]],\n\n        [[1.0000e+00],\n         [1.0000e+00],\n         [1.0000e+00],\n         ...,\n         [1.0000e+00],\n         [1.0000e+00],\n         [1.0000e+00]],\n\n        [[2.3232e-01],\n         [2.3232e-01],\n         [2.3232e-01],\n         ...,\n         [2.3232e-01],\n         [2.3232e-01],\n         [2.3232e-01]],\n\n        ...,\n\n        [[9.9347e-01],\n         [9.9347e-01],\n         [9.9347e-01],\n         ...,\n         [9.9347e-01],\n         [9.9347e-01],\n         [9.9347e-01]],\n\n        [[1.4795e-07],\n         [1.4795e-07],\n         [1.4795e-07],\n         ...,\n         [1.4795e-07],\n         [1.4795e-07],\n         [1.4795e-07]],\n\n        [[9.9571e-01],\n         [9.9571e-01],\n         [9.9571e-01],\n         ...,\n         [9.9571e-01],\n         [9.9571e-01],\n         [9.9571e-01]]], grad_fn=<DivBackward0>)\ntorch.Size([8, 256, 1])\ntensor([[[2.1615e-02],\n         [2.1615e-02],\n         [2.1615e-02],\n         ...,\n         [2.1615e-02],\n         [2.1615e-02],\n         [2.1615e-02]],\n\n        [[5.5381e-02],\n         [5.5381e-02],\n         [5.5381e-02],\n         ...,\n         [5.5381e-02],\n         [5.5381e-02],\n         [5.5381e-02]],\n\n        [[4.6988e-13],\n         [4.6988e-13],\n         [4.6988e-13],\n         ...,\n         [4.6988e-13],\n         [4.6988e-13],\n         [4.6988e-13]],\n\n        ...,\n\n        [[2.7593e-02],\n         [2.7593e-02],\n         [2.7593e-02],\n         ...,\n         [2.7593e-02],\n         [2.7593e-02],\n         [2.7593e-02]],\n\n        [[7.7169e-01],\n         [7.7169e-01],\n         [7.7169e-01],\n         ...,\n         [7.7169e-01],\n         [7.7169e-01],\n         [7.7169e-01]],\n\n        [[1.0000e+00],\n         [1.0000e+00],\n         [1.0000e+00],\n         ...,\n         [1.0000e+00],\n         [1.0000e+00],\n         [1.0000e+00]]], grad_fn=<DivBackward0>)\ntorch.Size([8, 256, 1])\ntensor([[[1.6105e-03],\n         [1.6105e-03],\n         [1.6105e-03],\n         ...,\n         [1.6105e-03],\n         [1.6105e-03],\n         [1.6105e-03]],\n\n        [[2.3682e-16],\n         [2.3682e-16],\n         [2.3682e-16],\n         ...,\n         [2.3682e-16],\n         [2.3682e-16],\n         [2.3682e-16]],\n\n        [[9.4187e-01],\n         [9.4187e-01],\n         [9.4187e-01],\n         ...,\n         [9.4187e-01],\n         [9.4187e-01],\n         [9.4187e-01]],\n\n        ...,\n\n        [[9.3344e-03],\n         [9.3344e-03],\n         [9.3344e-03],\n         ...,\n         [9.3344e-03],\n         [9.3344e-03],\n         [9.3344e-03]],\n\n        [[4.6511e-02],\n         [4.6511e-02],\n         [4.6511e-02],\n         ...,\n         [4.6511e-02],\n         [4.6511e-02],\n         [4.6511e-02]],\n\n        [[7.9550e-01],\n         [7.9550e-01],\n         [7.9550e-01],\n         ...,\n         [7.9550e-01],\n         [7.9550e-01],\n         [7.9550e-01]]], grad_fn=<DivBackward0>)\ntorch.Size([8, 256, 1])\ntensor([[[9.8068e-06],\n         [9.8068e-06],\n         [9.8068e-06],\n         ...,\n         [9.8068e-06],\n         [9.8068e-06],\n         [9.8068e-06]],\n\n        [[7.2926e-02],\n         [7.2926e-02],\n         [7.2926e-02],\n         ...,\n         [7.2926e-02],\n         [7.2926e-02],\n         [7.2926e-02]],\n\n        [[5.4587e-03],\n         [5.4587e-03],\n         [5.4587e-03],\n         ...,\n         [5.4587e-03],\n         [5.4587e-03],\n         [5.4587e-03]],\n\n        ...,\n\n        [[2.5337e-05],\n         [2.5337e-05],\n         [2.5337e-05],\n         ...,\n         [2.5337e-05],\n         [2.5337e-05],\n         [2.5337e-05]],\n\n        [[3.1844e-10],\n         [3.1844e-10],\n         [3.1844e-10],\n         ...,\n         [3.1844e-10],\n         [3.1844e-10],\n         [3.1844e-10]],\n\n        [[1.7571e-08],\n         [1.7571e-08],\n         [1.7571e-08],\n         ...,\n         [1.7571e-08],\n         [1.7571e-08],\n         [1.7571e-08]]], grad_fn=<DivBackward0>)\ntorch.Size([8, 256, 1])\ntensor([[[9.0712e-01],\n         [9.0712e-01],\n         [9.0712e-01],\n         ...,\n         [9.0712e-01],\n         [9.0712e-01],\n         [9.0712e-01]],\n\n        [[9.7148e-04],\n         [9.7148e-04],\n         [9.7148e-04],\n         ...,\n         [9.7148e-04],\n         [9.7148e-04],\n         [9.7148e-04]],\n\n        [[1.0000e+00],\n         [1.0000e+00],\n         [1.0000e+00],\n         ...,\n         [1.0000e+00],\n         [1.0000e+00],\n         [1.0000e+00]],\n\n        ...,\n\n        [[4.6086e-08],\n         [4.6086e-08],\n         [4.6086e-08],\n         ...,\n         [4.6086e-08],\n         [4.6086e-08],\n         [4.6086e-08]],\n\n        [[1.1207e-01],\n         [1.1207e-01],\n         [1.1207e-01],\n         ...,\n         [1.1207e-01],\n         [1.1207e-01],\n         [1.1207e-01]],\n\n        [[9.9780e-01],\n         [9.9780e-01],\n         [9.9780e-01],\n         ...,\n         [9.9780e-01],\n         [9.9780e-01],\n         [9.9780e-01]]], grad_fn=<DivBackward0>)\ntorch.Size([8, 256, 1])\n"
     ]
    }
   ],
   "source": [
    "features_res = []\n",
    "print(mult_factor)\n",
    "for id,feature in enumerate(features_H):\n",
    "    new_feature = feature*mult_factor[:,id].view(batchsize,1,1).expand(features_H[id].shape)\n",
    "    print(new_feature/feature)\n",
    "    print(new_feature.shape)\n",
    "    features_res.append(new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8df5418b9f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_H\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "features_H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[ 1.8564],\n",
       "         [ 0.4382],\n",
       "         [ 0.8485],\n",
       "         ...,\n",
       "         [-0.3001],\n",
       "         [ 1.2031],\n",
       "         [ 0.5020]],\n",
       "\n",
       "        [[ 0.3259],\n",
       "         [ 2.2329],\n",
       "         [ 0.1460],\n",
       "         ...,\n",
       "         [ 1.9029],\n",
       "         [ 0.0077],\n",
       "         [-2.3000]],\n",
       "\n",
       "        [[-1.4101],\n",
       "         [ 0.3413],\n",
       "         [-0.2845],\n",
       "         ...,\n",
       "         [-0.8871],\n",
       "         [-1.3615],\n",
       "         [-0.7424]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3400],\n",
       "         [-0.1131],\n",
       "         [ 0.8354],\n",
       "         ...,\n",
       "         [ 1.2913],\n",
       "         [-0.1840],\n",
       "         [ 0.5769]],\n",
       "\n",
       "        [[-0.0572],\n",
       "         [ 1.6035],\n",
       "         [ 1.0149],\n",
       "         ...,\n",
       "         [-0.1353],\n",
       "         [-0.7461],\n",
       "         [ 0.5826]],\n",
       "\n",
       "        [[-2.1842],\n",
       "         [ 0.7432],\n",
       "         [-0.4142],\n",
       "         ...,\n",
       "         [-0.1917],\n",
       "         [ 0.9167],\n",
       "         [-1.3274]]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "features_H[id]"
   ]
  }
 ]
}