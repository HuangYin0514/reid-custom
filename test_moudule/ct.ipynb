{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature_Fusion_Module(\n  (fc1): Linear(in_features=512, out_features=6, bias=True)\n)\ntorch.Size([8, 512])\ntensor([[3.4649e-02, 9.6369e-01, 1.0000e+00, 1.0000e+00, 9.9979e-01, 9.2831e-03],\n        [1.5973e-13, 9.9944e-01, 1.1512e-07, 1.0000e+00, 9.9882e-01, 8.8866e-13],\n        [9.9998e-01, 5.5238e-03, 1.9316e-11, 1.1402e-02, 3.1090e-13, 1.5034e-04],\n        [1.0000e+00, 1.8289e-03, 6.5744e-07, 4.3585e-02, 3.8857e-12, 1.0000e+00],\n        [3.7716e-06, 1.0000e+00, 9.9625e-01, 9.9985e-01, 2.7275e-11, 1.0000e+00],\n        [2.1599e-01, 2.6010e-01, 9.9918e-01, 2.8339e-02, 4.8816e-02, 1.0000e+00],\n        [1.0000e+00, 9.8869e-01, 6.9431e-06, 3.8659e-04, 8.7119e-01, 2.3240e-04],\n        [9.9999e-01, 9.9997e-01, 9.9160e-01, 4.6477e-02, 2.2280e-14, 8.1987e-01]],\n       grad_fn=<SigmoidBackward>)\ntorch.Size([8, 6])\ncomplete check.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        if m.affine:\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class Feature_Fusion_Module(nn.Module):\n",
    "    # 自定义特征融合模块\n",
    "    def __init__(self, ** kwargs):\n",
    "        super(Feature_Fusion_Module, self).__init__()\n",
    "        # Classifier for each stripe\n",
    "        self.fc1 = nn.Linear(512, 6)\n",
    "        self.fc1.apply(weights_init_kaiming)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "ffm = Feature_Fusion_Module()\n",
    "print(ffm)\n",
    "rd = torch.randn(batchsize, 512)\n",
    "print(rd.shape)\n",
    "res = ffm(rd)\n",
    "print(res)\n",
    "print(res.shape)\n",
    "print('complete check.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0346, 0.9637, 1.0000, 1.0000, 0.9998, 0.0093],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "res[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=8"
   ]
  },
  {
   "source": [
    "features_H = []  # contains 6 ([N, 256, 1])\n",
    "for i in range(6):\n",
    "    stripe_features_H = torch.randn(8,256,1)\n",
    "    features_H.append(stripe_features_H)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 2.3334,  0.9977,  0.8775,  0.4639,  0.0664, -1.1411],\n",
       "        [ 1.2668, -0.6134, -1.5213, -1.0079,  0.1921, -0.5048],\n",
       "        [ 0.6378,  1.6792,  1.6342, -1.1045, -0.8049, -0.3469],\n",
       "        [ 0.9840,  1.0953,  1.1998,  0.5224,  0.6483, -2.3979],\n",
       "        [ 0.2647,  1.1764, -0.1680,  0.2378,  0.4519,  0.0712],\n",
       "        [ 2.0797,  0.2940, -0.7968,  0.0872, -0.9600, -0.4466],\n",
       "        [ 0.7881,  0.8804, -1.4072, -0.8505,  1.8725,  0.2865],\n",
       "        [-0.5789,  0.2964,  1.5520, -0.4665,  1.1704,  1.0765]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "mult_factor = torch.randn(8,6)\n",
    "mult_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "mult_factor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "mult_factor[:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "features_H[0].shape\n",
    "features_H[0].view(8,-1).shape\n",
    "(features_H[0]*mult_factor[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (6) at non-singleton dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-72ee6d5415d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_H\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmult_factor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_H\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmult_factor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print((features_H[i].view(batchsize,-1)*mult_factor[:][i]).shape)\n",
    "    print(features_H[i].view(batchsize,-1)*mult_factor[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 2.3334,  0.9977,  0.8775,  0.4639,  0.0664, -1.1411])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "features_H[i].view(batchsize,-1).shape\n",
    "mult_factor[:][0].shape\n",
    "mult_factor[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "features_H[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "mult_factor[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 2.3334,  0.9977,  0.8775,  0.4639,  0.0664, -1.1411],\n",
       "        [ 1.2668, -0.6134, -1.5213, -1.0079,  0.1921, -0.5048],\n",
       "        [ 0.6378,  1.6792,  1.6342, -1.1045, -0.8049, -0.3469],\n",
       "        [ 0.9840,  1.0953,  1.1998,  0.5224,  0.6483, -2.3979],\n",
       "        [ 0.2647,  1.1764, -0.1680,  0.2378,  0.4519,  0.0712],\n",
       "        [ 2.0797,  0.2940, -0.7968,  0.0872, -0.9600, -0.4466],\n",
       "        [ 0.7881,  0.8804, -1.4072, -0.8505,  1.8725,  0.2865],\n",
       "        [-0.5789,  0.2964,  1.5520, -0.4665,  1.1704,  1.0765]])"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "mult_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([ 2.3334,  1.2668,  0.6378,  0.9840,  0.2647,  2.0797,  0.7881, -0.5789]),\n",
       " torch.Size([8]))"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "mult_factor[:,0],mult_factor[:,0].shape,features_H[i].view(batchsize,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (8) at non-singleton dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-d2aeee022062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures_H\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmult_factor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (8) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "features_H[i].view(batchsize,-1)*mult_factor[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (256) must match the existing size (8) at non-singleton dimension 1.  Target sizes: [8, 256].  Tensor sizes: [8]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-41596169cfb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmult_factor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_H\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (256) must match the existing size (8) at non-singleton dimension 1.  Target sizes: [8, 256].  Tensor sizes: [8]"
     ]
    }
   ],
   "source": [
    "mult_factor[:,0].expand_as(features_H[i].view(batchsize,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5531, -0.9327,  0.2130,  ...,  0.8494,  2.3303,  2.2622],\n",
       "        [-0.2042, -0.1271,  0.4650,  ..., -0.4667, -2.0964, -1.0976],\n",
       "        [ 0.5501,  0.3041, -0.4537,  ...,  0.1158,  0.3765, -0.1287],\n",
       "        ...,\n",
       "        [ 0.4249, -2.6174, -1.7900,  ...,  1.4845,  0.6306, -1.7327],\n",
       "        [ 0.3420, -0.3949,  0.6263,  ..., -0.5655, -0.8899,  0.3292],\n",
       "        [-0.3473,  0.2408, -0.3961,  ...,  0.3422, -0.5082, -0.0835]])"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "features_H[i].view(batchsize,-1)*mult_factor[:,0].view(batchsize,-1).expand(-1,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 2.3334,  2.3334,  2.3334,  ...,  2.3334,  2.3334,  2.3334],\n",
       "         [ 1.2668,  1.2668,  1.2668,  ...,  1.2668,  1.2668,  1.2668],\n",
       "         [ 0.6378,  0.6378,  0.6378,  ...,  0.6378,  0.6378,  0.6378],\n",
       "         ...,\n",
       "         [ 2.0797,  2.0797,  2.0797,  ...,  2.0797,  2.0797,  2.0797],\n",
       "         [ 0.7881,  0.7881,  0.7881,  ...,  0.7881,  0.7881,  0.7881],\n",
       "         [-0.5789, -0.5789, -0.5789,  ..., -0.5789, -0.5789, -0.5789]]),\n",
       " tensor([[-0.2370, -0.3997,  0.0913,  ...,  0.3640,  0.9987,  0.9695],\n",
       "         [-0.1612, -0.1003,  0.3671,  ..., -0.3684, -1.6549, -0.8664],\n",
       "         [ 0.8624,  0.4768, -0.7113,  ...,  0.1816,  0.5903, -0.2018],\n",
       "         ...,\n",
       "         [ 0.2043, -1.2585, -0.8607,  ...,  0.7138,  0.3032, -0.8332],\n",
       "         [ 0.4340, -0.5011,  0.7948,  ..., -0.7176, -1.1292,  0.4178],\n",
       "         [ 0.5998, -0.4159,  0.6842,  ..., -0.5911,  0.8778,  0.1442]]))"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "mult_factor[:,0].view(batchsize,-1).expand(-1,256),features_H[i].view(batchsize,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.5530158000000001"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "2.3334*-0.2370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-0.5531, -0.9327,  0.2130,  ...,  0.8494,  2.3303,  2.2622],\n",
       "        [-0.2042, -0.1271,  0.4650,  ..., -0.4667, -2.0964, -1.0976],\n",
       "        [ 0.5501,  0.3041, -0.4537,  ...,  0.1158,  0.3765, -0.1287],\n",
       "        ...,\n",
       "        [ 0.4249, -2.6174, -1.7900,  ...,  1.4845,  0.6306, -1.7327],\n",
       "        [ 0.3420, -0.3949,  0.6263,  ..., -0.5655, -0.8899,  0.3292],\n",
       "        [-0.3473,  0.2408, -0.3961,  ...,  0.3422, -0.5082, -0.0835]])"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "features_H[i].view(batchsize,-1)*mult_factor[:,0].view(batchsize,-1).expand(features_H[i].view(batchsize,-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0453,  0.3860,  0.0805,  0.8701],\n",
       "        [-1.2264, -0.3673, -0.0276, -1.6460],\n",
       "        [ 0.2817, -0.4221,  0.4141, -0.3153]])"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "t = torch.randn(3,4)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(0.0453),\n",
       " tensor([0.0453, 0.3860, 0.0805, 0.8701]),\n",
       " tensor([ 0.0453, -1.2264,  0.2817]))"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "t[0][0],t[:][0],t[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0.0453, 0.3860, 0.0805, 0.8701]),\n",
       " tensor([0.0453, 0.3860, 0.0805, 0.8701]))"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "t[0][:],t[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.15124555160142347"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "(64.7-56.2 )/56.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}