{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pcb_custom'...\r\n",
      "remote: Enumerating objects: 142, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (142/142), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (99/99), done.\u001b[K\r\n",
      "remote: Total 142 (delta 65), reused 110 (delta 33), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (142/142), 34.44 KiB | 11.48 MiB/s, done.\r\n",
      "Resolving deltas: 100% (65/65), done.\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf pcb_custom\n",
    "!git clone https://github.com/HuangYin0514/pcb_custom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/pcb_custom\n"
     ]
    }
   ],
   "source": [
    "cd ./pcb_custom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/datasets/market1501 -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data_transform.py \\\n",
    "--src_root_path=/kaggle/input/market1501/Market-1501-v15.09.15  \\\n",
    "--dst_root_path=/kaggle/working/datasets/market1501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, dataset='market1501', dataset_path='/kaggle/working/datasets/market1501', epochs=60, experiment='Res_net', learning_rate=0.1, save_path='./experiments', share_conv=False, stripes=6)\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\r\n",
      "100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 187MB/s]\r\n",
      "2020-05-08 08:35:44 ----------\r\n",
      "2020-05-08 08:35:44 {'experiment': 'Res_net', 'save_path': './experiments', 'dataset': 'market1501', 'dataset_path': '/kaggle/working/datasets/market1501', 'batch_size': 64, 'learning_rate': 0.1, 'epochs': 60, 'share_conv': False, 'stripes': 6}\r\n",
      "2020-05-08 08:35:44 Epoch 1/60\r\n",
      "2020-05-08 08:37:13 Training Loss: 6.6573\r\n",
      "2020-05-08 08:37:13 ----------\r\n",
      "2020-05-08 08:37:13 Epoch 2/60\r\n",
      "2020-05-08 08:38:41 Training Loss: 5.6651\r\n",
      "2020-05-08 08:38:41 ----------\r\n",
      "2020-05-08 08:38:41 Epoch 3/60\r\n",
      "2020-05-08 08:40:09 Training Loss: 4.3464\r\n",
      "2020-05-08 08:40:09 ----------\r\n",
      "2020-05-08 08:40:09 Epoch 4/60\r\n",
      "2020-05-08 08:41:38 Training Loss: 3.1138\r\n",
      "2020-05-08 08:41:38 ----------\r\n",
      "2020-05-08 08:41:38 Epoch 5/60\r\n",
      "2020-05-08 08:43:06 Training Loss: 2.1884\r\n",
      "2020-05-08 08:43:06 ----------\r\n",
      "2020-05-08 08:43:06 Epoch 6/60\r\n",
      "2020-05-08 08:44:34 Training Loss: 1.5365\r\n",
      "2020-05-08 08:44:34 ----------\r\n",
      "2020-05-08 08:44:34 Epoch 7/60\r\n",
      "2020-05-08 08:46:02 Training Loss: 1.1166\r\n",
      "2020-05-08 08:46:02 ----------\r\n",
      "2020-05-08 08:46:02 Epoch 8/60\r\n",
      "2020-05-08 08:47:30 Training Loss: 0.8459\r\n",
      "2020-05-08 08:47:30 ----------\r\n",
      "2020-05-08 08:47:30 Epoch 9/60\r\n",
      "2020-05-08 08:48:58 Training Loss: 0.6311\r\n",
      "2020-05-08 08:48:58 ----------\r\n",
      "2020-05-08 08:48:58 Epoch 10/60\r\n",
      "2020-05-08 08:50:26 Training Loss: 0.5240\r\n",
      "2020-05-08 08:50:26 ----------\r\n",
      "2020-05-08 08:50:26 Epoch 11/60\r\n",
      "2020-05-08 08:51:54 Training Loss: 0.4005\r\n",
      "2020-05-08 08:51:54 ----------\r\n",
      "2020-05-08 08:51:54 Epoch 12/60\r\n",
      "2020-05-08 08:53:22 Training Loss: 0.3367\r\n",
      "2020-05-08 08:53:22 ----------\r\n",
      "2020-05-08 08:53:22 Epoch 13/60\r\n",
      "2020-05-08 08:54:50 Training Loss: 0.2834\r\n",
      "2020-05-08 08:54:50 ----------\r\n",
      "2020-05-08 08:54:50 Epoch 14/60\r\n",
      "2020-05-08 08:56:18 Training Loss: 0.2356\r\n",
      "2020-05-08 08:56:18 ----------\r\n",
      "2020-05-08 08:56:18 Epoch 15/60\r\n",
      "2020-05-08 08:57:46 Training Loss: 0.2171\r\n",
      "2020-05-08 08:57:46 ----------\r\n",
      "2020-05-08 08:57:46 Epoch 16/60\r\n",
      "2020-05-08 08:59:14 Training Loss: 0.1869\r\n",
      "2020-05-08 08:59:14 ----------\r\n",
      "2020-05-08 08:59:14 Epoch 17/60\r\n",
      "2020-05-08 09:00:42 Training Loss: 0.1779\r\n",
      "2020-05-08 09:00:42 ----------\r\n",
      "2020-05-08 09:00:42 Epoch 18/60\r\n",
      "2020-05-08 09:02:09 Training Loss: 0.1407\r\n",
      "2020-05-08 09:02:09 ----------\r\n",
      "2020-05-08 09:02:09 Epoch 19/60\r\n",
      "2020-05-08 09:03:37 Training Loss: 0.1292\r\n",
      "2020-05-08 09:03:37 ----------\r\n",
      "2020-05-08 09:03:37 Epoch 20/60\r\n",
      "2020-05-08 09:05:05 Training Loss: 0.1526\r\n",
      "2020-05-08 09:07:24 Testing: top1:72.24 top5:87.08 top10:91.15 mAP:50.60\r\n",
      "2020-05-08 09:07:24 ----------\r\n",
      "2020-05-08 09:07:24 Epoch 21/60\r\n",
      "2020-05-08 09:08:52 Training Loss: 0.1186\r\n",
      "2020-05-08 09:08:52 ----------\r\n",
      "2020-05-08 09:08:52 Epoch 22/60\r\n",
      "2020-05-08 09:10:20 Training Loss: 0.1292\r\n",
      "2020-05-08 09:10:20 ----------\r\n",
      "2020-05-08 09:10:20 Epoch 23/60\r\n",
      "2020-05-08 09:11:48 Training Loss: 0.1550\r\n",
      "2020-05-08 09:11:48 ----------\r\n",
      "2020-05-08 09:11:48 Epoch 24/60\r\n",
      "2020-05-08 09:13:16 Training Loss: 0.1041\r\n",
      "2020-05-08 09:13:16 ----------\r\n",
      "2020-05-08 09:13:16 Epoch 25/60\r\n",
      "2020-05-08 09:14:44 Training Loss: 0.1077\r\n",
      "2020-05-08 09:14:44 ----------\r\n",
      "2020-05-08 09:14:44 Epoch 26/60\r\n",
      "2020-05-08 09:16:12 Training Loss: 0.0871\r\n",
      "2020-05-08 09:16:12 ----------\r\n",
      "2020-05-08 09:16:12 Epoch 27/60\r\n",
      "2020-05-08 09:17:40 Training Loss: 0.0966\r\n",
      "2020-05-08 09:17:40 ----------\r\n",
      "2020-05-08 09:17:40 Epoch 28/60\r\n",
      "2020-05-08 09:19:08 Training Loss: 0.0653\r\n",
      "2020-05-08 09:19:08 ----------\r\n",
      "2020-05-08 09:19:08 Epoch 29/60\r\n",
      "2020-05-08 09:20:36 Training Loss: 0.0531\r\n",
      "2020-05-08 09:20:36 ----------\r\n",
      "2020-05-08 09:20:36 Epoch 30/60\r\n",
      "2020-05-08 09:22:04 Training Loss: 0.0318\r\n",
      "2020-05-08 09:22:04 ----------\r\n",
      "2020-05-08 09:22:04 Epoch 31/60\r\n",
      "2020-05-08 09:23:32 Training Loss: 0.0169\r\n",
      "2020-05-08 09:23:32 ----------\r\n",
      "2020-05-08 09:23:32 Epoch 32/60\r\n",
      "2020-05-08 09:25:00 Training Loss: 0.0325\r\n",
      "2020-05-08 09:25:00 ----------\r\n",
      "2020-05-08 09:25:00 Epoch 33/60\r\n",
      "2020-05-08 09:26:28 Training Loss: 0.0219\r\n",
      "2020-05-08 09:26:28 ----------\r\n",
      "2020-05-08 09:26:28 Epoch 34/60\r\n",
      "2020-05-08 09:27:56 Training Loss: 0.0230\r\n",
      "2020-05-08 09:27:56 ----------\r\n",
      "2020-05-08 09:27:56 Epoch 35/60\r\n",
      "2020-05-08 09:29:25 Training Loss: 0.0255\r\n",
      "2020-05-08 09:29:25 ----------\r\n",
      "2020-05-08 09:29:25 Epoch 36/60\r\n",
      "2020-05-08 09:30:52 Training Loss: 0.0263\r\n",
      "2020-05-08 09:30:52 ----------\r\n",
      "2020-05-08 09:30:52 Epoch 37/60\r\n",
      "2020-05-08 09:32:20 Training Loss: 0.0431\r\n",
      "2020-05-08 09:32:20 ----------\r\n",
      "2020-05-08 09:32:20 Epoch 38/60\r\n",
      "2020-05-08 09:33:48 Training Loss: 0.1392\r\n",
      "2020-05-08 09:33:48 ----------\r\n",
      "2020-05-08 09:33:48 Epoch 39/60\r\n",
      "2020-05-08 09:35:16 Training Loss: 0.3331\r\n",
      "2020-05-08 09:35:16 ----------\r\n",
      "2020-05-08 09:35:16 Epoch 40/60\r\n",
      "2020-05-08 09:36:44 Training Loss: 0.3022\r\n",
      "2020-05-08 09:39:02 Testing: top1:65.41 top5:82.78 top10:87.68 mAP:42.91\r\n",
      "2020-05-08 09:39:02 ----------\r\n",
      "2020-05-08 09:39:02 Epoch 41/60\r\n",
      "2020-05-08 09:40:30 Training Loss: 0.0762\r\n",
      "2020-05-08 09:40:30 ----------\r\n",
      "2020-05-08 09:40:30 Epoch 42/60\r\n",
      "2020-05-08 09:41:58 Training Loss: 0.0181\r\n",
      "2020-05-08 09:41:58 ----------\r\n",
      "2020-05-08 09:41:58 Epoch 43/60\r\n",
      "2020-05-08 09:43:26 Training Loss: 0.0138\r\n",
      "2020-05-08 09:43:26 ----------\r\n",
      "2020-05-08 09:43:26 Epoch 44/60\r\n",
      "2020-05-08 09:44:54 Training Loss: 0.0112\r\n",
      "2020-05-08 09:44:54 ----------\r\n",
      "2020-05-08 09:44:54 Epoch 45/60\r\n",
      "2020-05-08 09:46:22 Training Loss: 0.0101\r\n",
      "2020-05-08 09:46:22 ----------\r\n",
      "2020-05-08 09:46:22 Epoch 46/60\r\n",
      "2020-05-08 09:47:50 Training Loss: 0.0086\r\n",
      "2020-05-08 09:47:50 ----------\r\n",
      "2020-05-08 09:47:50 Epoch 47/60\r\n",
      "2020-05-08 09:49:18 Training Loss: 0.0088\r\n",
      "2020-05-08 09:49:18 ----------\r\n",
      "2020-05-08 09:49:18 Epoch 48/60\r\n",
      "2020-05-08 09:50:46 Training Loss: 0.0083\r\n",
      "2020-05-08 09:50:46 ----------\r\n",
      "2020-05-08 09:50:46 Epoch 49/60\r\n",
      "2020-05-08 09:52:13 Training Loss: 0.0079\r\n",
      "2020-05-08 09:52:13 ----------\r\n",
      "2020-05-08 09:52:13 Epoch 50/60\r\n",
      "2020-05-08 09:53:41 Training Loss: 0.0079\r\n",
      "2020-05-08 09:53:41 ----------\r\n",
      "2020-05-08 09:53:41 Epoch 51/60\r\n",
      "2020-05-08 09:55:09 Training Loss: 0.0080\r\n",
      "2020-05-08 09:55:09 ----------\r\n",
      "2020-05-08 09:55:09 Epoch 52/60\r\n",
      "2020-05-08 09:56:37 Training Loss: 0.0077\r\n",
      "2020-05-08 09:56:37 ----------\r\n",
      "2020-05-08 09:56:37 Epoch 53/60\r\n",
      "2020-05-08 09:58:05 Training Loss: 0.0077\r\n",
      "2020-05-08 09:58:05 ----------\r\n",
      "2020-05-08 09:58:05 Epoch 54/60\r\n",
      "2020-05-08 09:59:32 Training Loss: 0.0082\r\n",
      "2020-05-08 09:59:32 ----------\r\n",
      "2020-05-08 09:59:32 Epoch 55/60\r\n",
      "2020-05-08 10:01:00 Training Loss: 0.0081\r\n",
      "2020-05-08 10:01:00 ----------\r\n",
      "2020-05-08 10:01:00 Epoch 56/60\r\n",
      "2020-05-08 10:02:28 Training Loss: 0.0081\r\n",
      "2020-05-08 10:02:28 ----------\r\n",
      "2020-05-08 10:02:28 Epoch 57/60\r\n",
      "2020-05-08 10:03:56 Training Loss: 0.0083\r\n",
      "2020-05-08 10:03:56 ----------\r\n",
      "2020-05-08 10:03:56 Epoch 58/60\r\n",
      "2020-05-08 10:05:24 Training Loss: 0.0085\r\n",
      "2020-05-08 10:05:24 ----------\r\n",
      "2020-05-08 10:05:24 Epoch 59/60\r\n",
      "2020-05-08 10:06:52 Training Loss: 0.0084\r\n",
      "2020-05-08 10:06:52 ----------\r\n",
      "2020-05-08 10:06:52 Epoch 60/60\r\n",
      "2020-05-08 10:08:20 Training Loss: 0.0086\r\n",
      "2020-05-08 10:10:37 Testing: top1:78.89 top5:90.41 top10:93.41 mAP:59.20\r\n",
      "2020-05-08 10:10:37 ----------\r\n",
      "2020-05-08 10:10:37 Training complete in 94m 53s\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--experiment=Res_net \\\n",
    "--dataset_path=/kaggle/working/datasets/market1501 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/pcb_custom\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar zcf ../experiments.tar experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dat*  pcb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
