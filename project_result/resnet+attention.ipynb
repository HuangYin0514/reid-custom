{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pcb_custom'...\r\n",
      "remote: Enumerating objects: 171, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (171/171), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (118/118), done.\u001b[K\r\n",
      "remote: Total 171 (delta 83), reused 130 (delta 42), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (171/171), 39.10 KiB | 548.00 KiB/s, done.\r\n",
      "Resolving deltas: 100% (83/83), done.\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf pcb_custom\n",
    "!git clone https://github.com/HuangYin0514/pcb_custom.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/pcb_custom\n"
     ]
    }
   ],
   "source": [
    "cd ./pcb_custom/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/datasets/market1501 -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python data_transform.py \\\n",
    "--src_root_path=/kaggle/input/market1501/Market-1501-v15.09.15  \\\n",
    "--dst_root_path=/kaggle/working/datasets/market1501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, dataset='market1501', dataset_path='/kaggle/working/datasets/market1501', epochs=60, experiment='Resnet_self_attention', learning_rate=0.1, save_path='./experiments', share_conv=False, stripes=6)\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\r\n",
      "100%|███████████████████████████████████████| 97.8M/97.8M [00:00<00:00, 191MB/s]\r\n",
      "2020-05-09 06:20:28 ----------\r\n",
      "2020-05-09 06:20:28 {'experiment': 'Resnet_self_attention', 'save_path': './experiments', 'dataset': 'market1501', 'dataset_path': '/kaggle/working/datasets/market1501', 'batch_size': 64, 'learning_rate': 0.1, 'epochs': 60, 'share_conv': False, 'stripes': 6}\r\n",
      "2020-05-09 06:20:28 Epoch 1/60\r\n",
      "2020-05-09 06:22:02 Training Loss: 6.6645\r\n",
      "2020-05-09 06:22:02 ----------\r\n",
      "2020-05-09 06:22:02 Epoch 2/60\r\n",
      "2020-05-09 06:23:34 Training Loss: 5.8816\r\n",
      "2020-05-09 06:23:34 ----------\r\n",
      "2020-05-09 06:23:34 Epoch 3/60\r\n",
      "2020-05-09 06:25:06 Training Loss: 5.0182\r\n",
      "2020-05-09 06:25:06 ----------\r\n",
      "2020-05-09 06:25:06 Epoch 4/60\r\n",
      "2020-05-09 06:26:37 Training Loss: 3.8349\r\n",
      "2020-05-09 06:26:37 ----------\r\n",
      "2020-05-09 06:26:37 Epoch 5/60\r\n",
      "2020-05-09 06:28:09 Training Loss: 2.7678\r\n",
      "2020-05-09 06:28:09 ----------\r\n",
      "2020-05-09 06:28:09 Epoch 6/60\r\n",
      "2020-05-09 06:29:42 Training Loss: 1.9484\r\n",
      "2020-05-09 06:29:42 ----------\r\n",
      "2020-05-09 06:29:42 Epoch 7/60\r\n",
      "2020-05-09 06:31:14 Training Loss: 1.3943\r\n",
      "2020-05-09 06:31:14 ----------\r\n",
      "2020-05-09 06:31:14 Epoch 8/60\r\n",
      "2020-05-09 06:32:46 Training Loss: 1.0470\r\n",
      "2020-05-09 06:32:46 ----------\r\n",
      "2020-05-09 06:32:46 Epoch 9/60\r\n",
      "2020-05-09 06:34:18 Training Loss: 0.7811\r\n",
      "2020-05-09 06:34:18 ----------\r\n",
      "2020-05-09 06:34:18 Epoch 10/60\r\n",
      "2020-05-09 06:35:50 Training Loss: 0.6145\r\n",
      "2020-05-09 06:35:50 ----------\r\n",
      "2020-05-09 06:35:50 Epoch 11/60\r\n",
      "2020-05-09 06:37:22 Training Loss: 0.5025\r\n",
      "2020-05-09 06:37:22 ----------\r\n",
      "2020-05-09 06:37:22 Epoch 12/60\r\n",
      "2020-05-09 06:38:54 Training Loss: 0.4152\r\n",
      "2020-05-09 06:38:54 ----------\r\n",
      "2020-05-09 06:38:54 Epoch 13/60\r\n",
      "2020-05-09 06:40:26 Training Loss: 0.3503\r\n",
      "2020-05-09 06:40:26 ----------\r\n",
      "2020-05-09 06:40:26 Epoch 14/60\r\n",
      "2020-05-09 06:41:58 Training Loss: 0.2883\r\n",
      "2020-05-09 06:41:58 ----------\r\n",
      "2020-05-09 06:41:58 Epoch 15/60\r\n",
      "2020-05-09 06:43:30 Training Loss: 0.2653\r\n",
      "2020-05-09 06:43:30 ----------\r\n",
      "2020-05-09 06:43:30 Epoch 16/60\r\n",
      "2020-05-09 06:45:02 Training Loss: 0.2292\r\n",
      "2020-05-09 06:45:02 ----------\r\n",
      "2020-05-09 06:45:02 Epoch 17/60\r\n",
      "2020-05-09 06:46:34 Training Loss: 0.1794\r\n",
      "2020-05-09 06:46:34 ----------\r\n",
      "2020-05-09 06:46:34 Epoch 18/60\r\n",
      "2020-05-09 06:48:06 Training Loss: 0.1623\r\n",
      "2020-05-09 06:48:06 ----------\r\n",
      "2020-05-09 06:48:06 Epoch 19/60\r\n",
      "2020-05-09 06:49:38 Training Loss: 0.1579\r\n",
      "2020-05-09 06:49:38 ----------\r\n",
      "2020-05-09 06:49:38 Epoch 20/60\r\n",
      "2020-05-09 06:51:10 Training Loss: 0.1542\r\n",
      "2020-05-09 06:53:40 Testing: top1:67.58 top5:84.12 top10:89.52 mAP:47.51\r\n",
      "2020-05-09 06:53:40 ----------\r\n",
      "2020-05-09 06:53:40 Epoch 21/60\r\n",
      "2020-05-09 06:55:12 Training Loss: 0.1147\r\n",
      "2020-05-09 06:55:12 ----------\r\n",
      "2020-05-09 06:55:12 Epoch 22/60\r\n",
      "2020-05-09 06:56:44 Training Loss: 0.1163\r\n",
      "2020-05-09 06:56:44 ----------\r\n",
      "2020-05-09 06:56:44 Epoch 23/60\r\n",
      "2020-05-09 06:58:17 Training Loss: 0.1124\r\n",
      "2020-05-09 06:58:17 ----------\r\n",
      "2020-05-09 06:58:17 Epoch 24/60\r\n",
      "2020-05-09 06:59:49 Training Loss: 0.0908\r\n",
      "2020-05-09 06:59:49 ----------\r\n",
      "2020-05-09 06:59:49 Epoch 25/60\r\n",
      "2020-05-09 07:01:21 Training Loss: 0.1127\r\n",
      "2020-05-09 07:01:21 ----------\r\n",
      "2020-05-09 07:01:21 Epoch 26/60\r\n",
      "2020-05-09 07:02:53 Training Loss: 0.1281\r\n",
      "2020-05-09 07:02:53 ----------\r\n",
      "2020-05-09 07:02:53 Epoch 27/60\r\n",
      "2020-05-09 07:04:25 Training Loss: 0.1374\r\n",
      "2020-05-09 07:04:25 ----------\r\n",
      "2020-05-09 07:04:25 Epoch 28/60\r\n",
      "2020-05-09 07:05:57 Training Loss: 0.0901\r\n",
      "2020-05-09 07:05:57 ----------\r\n",
      "2020-05-09 07:05:57 Epoch 29/60\r\n",
      "2020-05-09 07:07:29 Training Loss: 0.1173\r\n",
      "2020-05-09 07:07:29 ----------\r\n",
      "2020-05-09 07:07:29 Epoch 30/60\r\n",
      "2020-05-09 07:09:01 Training Loss: 0.1680\r\n",
      "2020-05-09 07:09:01 ----------\r\n",
      "2020-05-09 07:09:01 Epoch 31/60\r\n",
      "2020-05-09 07:10:33 Training Loss: 0.1406\r\n",
      "2020-05-09 07:10:33 ----------\r\n",
      "2020-05-09 07:10:33 Epoch 32/60\r\n",
      "2020-05-09 07:12:05 Training Loss: 0.1400\r\n",
      "2020-05-09 07:12:05 ----------\r\n",
      "2020-05-09 07:12:05 Epoch 33/60\r\n",
      "2020-05-09 07:13:37 Training Loss: 0.1546\r\n",
      "2020-05-09 07:13:37 ----------\r\n",
      "2020-05-09 07:13:37 Epoch 34/60\r\n",
      "2020-05-09 07:15:09 Training Loss: 0.1121\r\n",
      "2020-05-09 07:15:09 ----------\r\n",
      "2020-05-09 07:15:09 Epoch 35/60\r\n",
      "2020-05-09 07:16:41 Training Loss: 0.1050\r\n",
      "2020-05-09 07:16:41 ----------\r\n",
      "2020-05-09 07:16:41 Epoch 36/60\r\n",
      "2020-05-09 07:18:14 Training Loss: 0.1220\r\n",
      "2020-05-09 07:18:14 ----------\r\n",
      "2020-05-09 07:18:14 Epoch 37/60\r\n",
      "2020-05-09 07:19:46 Training Loss: 0.1189\r\n",
      "2020-05-09 07:19:46 ----------\r\n",
      "2020-05-09 07:19:46 Epoch 38/60\r\n",
      "2020-05-09 07:21:18 Training Loss: 0.1481\r\n",
      "2020-05-09 07:21:18 ----------\r\n",
      "2020-05-09 07:21:18 Epoch 39/60\r\n",
      "2020-05-09 07:22:50 Training Loss: 0.1409\r\n",
      "2020-05-09 07:22:50 ----------\r\n",
      "2020-05-09 07:22:50 Epoch 40/60\r\n",
      "2020-05-09 07:24:22 Training Loss: 0.1338\r\n",
      "2020-05-09 07:26:53 Testing: top1:67.81 top5:83.97 top10:89.22 mAP:45.95\r\n",
      "2020-05-09 07:26:53 ----------\r\n",
      "2020-05-09 07:26:53 Epoch 41/60\r\n",
      "2020-05-09 07:28:25 Training Loss: 0.0396\r\n",
      "2020-05-09 07:28:25 ----------\r\n",
      "2020-05-09 07:28:25 Epoch 42/60\r\n",
      "2020-05-09 07:29:58 Training Loss: 0.0122\r\n",
      "2020-05-09 07:29:58 ----------\r\n",
      "2020-05-09 07:29:58 Epoch 43/60\r\n",
      "2020-05-09 07:31:30 Training Loss: 0.0093\r\n",
      "2020-05-09 07:31:30 ----------\r\n",
      "2020-05-09 07:31:30 Epoch 44/60\r\n",
      "2020-05-09 07:33:02 Training Loss: 0.0091\r\n",
      "2020-05-09 07:33:02 ----------\r\n",
      "2020-05-09 07:33:02 Epoch 45/60\r\n",
      "2020-05-09 07:34:34 Training Loss: 0.0083\r\n",
      "2020-05-09 07:34:34 ----------\r\n",
      "2020-05-09 07:34:34 Epoch 46/60\r\n",
      "2020-05-09 07:36:06 Training Loss: 0.0074\r\n",
      "2020-05-09 07:36:06 ----------\r\n",
      "2020-05-09 07:36:06 Epoch 47/60\r\n",
      "2020-05-09 07:37:38 Training Loss: 0.0073\r\n",
      "2020-05-09 07:37:38 ----------\r\n",
      "2020-05-09 07:37:38 Epoch 48/60\r\n",
      "2020-05-09 07:39:10 Training Loss: 0.0069\r\n",
      "2020-05-09 07:39:10 ----------\r\n",
      "2020-05-09 07:39:10 Epoch 49/60\r\n",
      "2020-05-09 07:40:42 Training Loss: 0.0068\r\n",
      "2020-05-09 07:40:42 ----------\r\n",
      "2020-05-09 07:40:42 Epoch 50/60\r\n",
      "2020-05-09 07:42:15 Training Loss: 0.0073\r\n",
      "2020-05-09 07:42:15 ----------\r\n",
      "2020-05-09 07:42:15 Epoch 51/60\r\n",
      "2020-05-09 07:43:47 Training Loss: 0.0069\r\n",
      "2020-05-09 07:43:47 ----------\r\n",
      "2020-05-09 07:43:47 Epoch 52/60\r\n",
      "2020-05-09 07:45:19 Training Loss: 0.0069\r\n",
      "2020-05-09 07:45:19 ----------\r\n",
      "2020-05-09 07:45:19 Epoch 53/60\r\n",
      "2020-05-09 07:46:51 Training Loss: 0.0072\r\n",
      "2020-05-09 07:46:51 ----------\r\n",
      "2020-05-09 07:46:51 Epoch 54/60\r\n",
      "2020-05-09 07:48:23 Training Loss: 0.0073\r\n",
      "2020-05-09 07:48:23 ----------\r\n",
      "2020-05-09 07:48:23 Epoch 55/60\r\n",
      "2020-05-09 07:49:55 Training Loss: 0.0074\r\n",
      "2020-05-09 07:49:55 ----------\r\n",
      "2020-05-09 07:49:55 Epoch 56/60\r\n",
      "2020-05-09 07:51:27 Training Loss: 0.0073\r\n",
      "2020-05-09 07:51:27 ----------\r\n",
      "2020-05-09 07:51:27 Epoch 57/60\r\n",
      "2020-05-09 07:52:59 Training Loss: 0.0076\r\n",
      "2020-05-09 07:52:59 ----------\r\n",
      "2020-05-09 07:52:59 Epoch 58/60\r\n",
      "2020-05-09 07:54:31 Training Loss: 0.0080\r\n",
      "2020-05-09 07:54:31 ----------\r\n",
      "2020-05-09 07:54:31 Epoch 59/60\r\n",
      "2020-05-09 07:56:03 Training Loss: 0.0081\r\n",
      "2020-05-09 07:56:03 ----------\r\n",
      "2020-05-09 07:56:03 Epoch 60/60\r\n",
      "2020-05-09 07:57:35 Training Loss: 0.0082\r\n",
      "2020-05-09 07:59:59 Testing: top1:76.48 top5:89.82 top10:93.23 mAP:57.51\r\n",
      "2020-05-09 07:59:59 ----------\r\n",
      "2020-05-09 07:59:59 Training complete in 99m 30s\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py \\\n",
    "--experiment=Resnet_self_attention \\\n",
    "--dataset_path=/kaggle/working/datasets/market1501 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/pcb_custom\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar zcf ../experiments.tar experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf datasets*  pcb_custom/experiments*  pcb_custom/project_result*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
